{"description": "This is a beginner friendly Redux workflow that integrates Flux Fill - The official flux fill model created by Black Forest Labs (original developers of Flux)\n\nIt allows you to take an image as input, and recreate a highly similar replicate.\nYou can also modify this workflow, and combine multiple images to create a blended mixture of both.\n\nPrerequisites:\n- Update ComfyUI to the latest version\n- Download flux redux safetensors file from:    https://huggingface.co/black-forest-labs/FLUX.1-Redux-dev\n- Place the redux model inside comfyui/models/style_models\n- Doanload the clip vision model from:  https://huggingface.co/google/siglip-so400m-patch14-384/tree/main\n\nLink to other Flux Tools beginner friendly workflows:\nFlux Fill (Inpaint) -  https://openart.ai/workflows/odam_ai/flux-fill-inpaint---official-flux-tools-by-bfl---beginner-friendly/8wIPSZy0aOuXsGfdfIVp\n\nFlux Fill (Outpaint) -  https://openart.ai/workflows/odam_ai/flux-fill-outpaint---official-flux-tools-by-bfl---beginner-friendly-edit/6CeBgmyrVDP35r4pO4S9\n\nFlux Depth ControlNet -  https://openart.ai/workflows/odam_ai/flux-tools-best-depth-controlnet---official-flux-tools-by-bfl---beginner-friendly/2UDeSn35mPGIEqT1tgYu\n\nFlux Canny ControlNet - https://openart.ai/workflows/odam_ai/flux-tools-best-canny-controlnet---official-flux-tools-by-bfl---beginner-friendly/O8aLfWdCOKGCyJX79Jm0\nFlux Redux -  https://openart.ai/workflows/odam_ai/flux-redux---official-flux-tools-by-bfl---beginner-friendly/tgGYqY7Kri5bMzaulHiI", "name": "Flux Redux - Official Flux Tools by BFL - Beginner Friendly", "stars": "5.0", "number_reviews": 0, "workflow_like": 11, "workflow_view": 4700, "workflow_download": 1400, "workflow_comment": 1, "author_workflow": 25, "author_download": 44000, "author_like": 419, "author_view": 142400, "url": "https://openart.ai/workflows/odam_ai/flux-redux---official-flux-tools-by-bfl---beginner-friendly/tgGYqY7Kri5bMzaulHiI", "workflow_json": {"last_node_id": 57, "last_link_id": 138, "nodes": [{"id": 8, "type": "VAEDecode", "pos": [1044, 461], "size": [210, 46], "flags": {}, "order": 15, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 137}, {"name": "vae", "type": "VAE", "link": 12}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [9], "slot_index": 0}], "properties": {"Node name for S&R": "VAEDecode"}, "widgets_values": []}, {"id": 9, "type": "SaveImage", "pos": [1487, -12], "size": [530, 560], "flags": {}, "order": 16, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 9}], "outputs": [], "properties": {"Node name for S&R": "SaveImage"}, "widgets_values": ["ComfyUI"]}, {"id": 10, "type": "VAELoader", "pos": [-43, 311], "size": [311.81634521484375, 60.429901123046875], "flags": {}, "order": 0, "mode": 0, "inputs": [], "outputs": [{"name": "VAE", "type": "VAE", "links": [12], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "VAELoader"}, "widgets_values": ["ae.safetensors"]}, {"id": 11, "type": "DualCLIPLoader", "pos": [-40, 160], "size": [315, 106], "flags": {}, "order": 1, "mode": 0, "inputs": [], "outputs": [{"name": "CLIP", "type": "CLIP", "links": [132, 135], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "DualCLIPLoader"}, "widgets_values": ["t5xxl_fp16.safetensors", "clip_l.safetensors", "flux"]}, {"id": 12, "type": "UNETLoader", "pos": [-48, 31], "size": [315, 82], "flags": {}, "order": 2, "mode": 0, "inputs": [], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [129], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "UNETLoader"}, "widgets_values": ["flux1-dev.sft", "fp8_e4m3fn"], "color": "#223", "bgcolor": "#335"}, {"id": 38, "type": "CLIPVisionLoader", "pos": [-38, 421], "size": [292.6253662109375, 58], "flags": {}, "order": 3, "mode": 0, "inputs": [], "outputs": [{"name": "CLIP_VISION", "type": "CLIP_VISION", "links": [117], "slot_index": 0}], "properties": {"Node name for S&R": "CLIPVisionLoader"}, "widgets_values": ["sigclip_patch14-384.safetensors"]}, {"id": 39, "type": "CLIPVisionEncode", "pos": [314, 490], "size": [290, 50], "flags": {}, "order": 12, "mode": 0, "inputs": [{"name": "clip_vision", "type": "CLIP_VISION", "link": 117}, {"name": "image", "type": "IMAGE", "link": 118}], "outputs": [{"name": "CLIP_VISION_OUTPUT", "type": "CLIP_VISION_OUTPUT", "links": [120], "slot_index": 0}], "properties": {"Node name for S&R": "CLIPVisionEncode"}, "widgets_values": []}, {"id": 41, "type": "StyleModelApply", "pos": [615, 259], "size": [320, 70], "flags": {}, "order": 13, "mode": 0, "inputs": [{"name": "conditioning", "type": "CONDITIONING", "link": 138}, {"name": "style_model", "type": "STYLE_MODEL", "link": 119}, {"name": "clip_vision_output", "type": "CLIP_VISION_OUTPUT", "link": 120, "shape": 7}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [130], "slot_index": 0}], "properties": {"Node name for S&R": "StyleModelApply"}, "widgets_values": []}, {"id": 42, "type": "StyleModelLoader", "pos": [-40, 527], "size": [340, 60], "flags": {}, "order": 4, "mode": 0, "inputs": [], "outputs": [{"name": "STYLE_MODEL", "type": "STYLE_MODEL", "links": [119]}], "properties": {"Node name for S&R": "StyleModelLoader"}, "widgets_values": ["flux1-redux-dev.safetensors"]}, {"id": 44, "type": "KSampler", "pos": [955, 146], "size": [315, 262], "flags": {}, "order": 14, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 129}, {"name": "positive", "type": "CONDITIONING", "link": 130}, {"name": "negative", "type": "CONDITIONING", "link": 136}, {"name": "latent_image", "type": "LATENT", "link": 125}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [137], "slot_index": 0}], "properties": {"Node name for S&R": "KSampler"}, "widgets_values": [986503058816153, "randomize", 25, 1, "euler", "normal", 1]}, {"id": 45, "type": "EmptyLatentImage", "pos": [312, 590], "size": [315, 106], "flags": {}, "order": 5, "mode": 0, "inputs": [], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [125], "slot_index": 0}], "properties": {"Node name for S&R": "EmptyLatentImage"}, "widgets_values": [1024, 1024, 1]}, {"id": 50, "type": "CLIPTextEncodeFlux", "pos": [310, 84], "size": [400, 200], "flags": {"collapsed": true}, "order": 11, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 135}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [136], "slot_index": 0}], "properties": {"Node name for S&R": "CLIPTextEncodeFlux"}, "widgets_values": ["", "", 3.5]}, {"id": 54, "type": "ImageComposite+", "pos": [747, 740], "size": [315, 170], "flags": {}, "order": 6, "mode": 0, "inputs": [{"name": "destination", "type": "IMAGE", "link": null}, {"name": "source", "type": "IMAGE", "link": null}, {"name": "mask", "type": "MASK", "link": null, "shape": 7}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": null}], "properties": {"Node name for S&R": "ImageComposite+"}, "widgets_values": [0, 0, 0, 0]}, {"id": 56, "type": "ImageCompositeMasked", "pos": [1129, 728], "size": [315, 146], "flags": {}, "order": 7, "mode": 0, "inputs": [{"name": "destination", "type": "IMAGE", "link": null}, {"name": "source", "type": "IMAGE", "link": null}, {"name": "mask", "type": "MASK", "link": null, "shape": 7}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": null}], "properties": {"Node name for S&R": "ImageCompositeMasked"}, "widgets_values": [0, 0, false]}, {"id": 57, "type": "ImageCompositeFromMaskBatch+", "pos": [1493, 622], "size": [428.4000244140625, 66], "flags": {}, "order": 8, "mode": 0, "inputs": [{"name": "image_from", "type": "IMAGE", "link": null}, {"name": "image_to", "type": "IMAGE", "link": null}, {"name": "mask", "type": "MASK", "link": null}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": null}], "properties": {"Node name for S&R": "ImageCompositeFromMaskBatch+"}, "widgets_values": []}, {"id": 40, "type": "LoadImage", "pos": [312, 137], "size": [280, 314], "flags": {}, "order": 9, "mode": 0, "inputs": [], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [118]}, {"name": "MASK", "type": "MASK", "links": null}], "properties": {"Node name for S&R": "LoadImage"}, "widgets_values": ["AGAVE2.jpg", "image"]}, {"id": 48, "type": "CLIPTextEncodeFlux", "pos": [311, 28], "size": [400, 200], "flags": {"collapsed": true}, "order": 10, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 132}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [138], "slot_index": 0}], "properties": {"Node name for S&R": "CLIPTextEncodeFlux"}, "widgets_values": ["", "", 3.5]}], "links": [[9, 8, 0, 9, 0, "IMAGE"], [12, 10, 0, 8, 1, "VAE"], [117, 38, 0, 39, 0, "CLIP_VISION"], [118, 40, 0, 39, 1, "IMAGE"], [119, 42, 0, 41, 1, "STYLE_MODEL"], [120, 39, 0, 41, 2, "CLIP_VISION_OUTPUT"], [125, 45, 0, 44, 3, "LATENT"], [129, 12, 0, 44, 0, "MODEL"], [130, 41, 0, 44, 1, "CONDITIONING"], [132, 11, 0, 48, 0, "CLIP"], [135, 11, 0, 50, 0, "CLIP"], [136, 50, 0, 44, 2, "CONDITIONING"], [137, 44, 0, 8, 0, "LATENT"], [138, 48, 0, 41, 0, "CONDITIONING"]], "groups": [], "config": {}, "extra": {"ds": {"scale": 0.9646149645000026, "offset": [379.1857383354141, 150.1430376444321]}, "groupNodes": {}}, "version": 0.4}}