{"description": "Intro\nHello there. I'm still kinda new to this, but want to share this workflow with people that I used to create a comic I made of my worst date ever lol.\nHopefully some of you will find this useful.\nI also made a video about making it you can check out. Going over the workflow, and shows the comic, with a voiceover, panel by panel at the end: https://youtu.be/yqSxxORksLE\n\nOverview\nSo this took me a couple months to do, mainly cause I had to learn ComfyUI. It took me a while to get comfortable in it. I tried many different workflows from others to try this before I made my own that best suited my needs.\n(Originally I was using an SDXL workflow with a load of ipadapters and controlNets, but I found a simpler workflow yielded better results.)\n\nAll the images were generated with ComfyUI, but I composed each panel in photoshop. Each character, background, object (and even the snot lol) were generated separately.\n\nI was using SD1.5 for the speed, (model: Arthemy Comics on civitai), as I had to make a lot of images, and each one took many many iterations of trial and error to get good enough image.\nIt took 4s for an SD1.5 to generate an image, where as SDXL took 40s, so was too slow to quickly iterate. So then I would only upscale the images I wanted to use in the comic. (Just bypass upscaler section when iterating.)\n(Apart from the sneezing images which are SDXL on a different model, because I did these first and couldn't get good enough results in SD1.5. So that's why the girl looks slightly different.)\n\nThe comic panels are all 1920x1080 because I made it more for visuals to go along with a video (linked below) to help tell my horrifying story, than for it to be a stand alone comic. I would of tried a more dynamic flow for the layout of the panels if it was to be a standard comic page.\n\nThere was loads of different challenges from getting decent poses, getting hands to be somewhat respectable (though still pretty bad haha), getting good expressions on the faces.\nBut the main one is consistent characters. (And I did it without training my own character loras.)\n\nConsistent characters\nSo the way I used to get consistent characters was using a mix of:\nimg2img (denoise: 0.7) with the same model posed into the position desired.\nThen using a weighted down character lora and a weighted down celeb name, to help give a consistent base.\nAnd finally a prompt with all the same details each time. (Well apart from changing expressions in the prompt each time.)\n\nThough not perfect, I think the results are pretty cool for what the AI can help us create.\n\nHere is the comic:", "name": "Easy Consistent Characters for Comics (No Lora Training!)", "stars": "5.0", "number_reviews": 0, "workflow_like": 87, "workflow_view": 14600, "workflow_download": 3600, "workflow_comment": 7, "author_workflow": 4, "author_download": 7400, "author_like": 163, "author_view": 29000, "url": "https://openart.ai/workflows/monkey_perky_22/easy-consistent-characters-for-comics-no-lora-training/NCgZ46G3ZedZU3OwrviL", "workflow_json": {"last_node_id": 32, "last_link_id": 80, "nodes": [{"id": 14, "type": "VAEEncodeTiled", "pos": [2423.7760981618685, 651.5563691014685], "size": {"0": 315, "1": 78}, "flags": {}, "order": 22, "mode": 0, "inputs": [{"name": "pixels", "type": "IMAGE", "link": 16}, {"name": "vae", "type": "VAE", "link": 17}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [21], "shape": 3}], "properties": {"Node name for S&R": "VAEEncodeTiled"}, "widgets_values": [512], "color": "#232", "bgcolor": "#353"}, {"id": 7, "type": "VAEDecode", "pos": [2816.7760981618685, 629.5563691014685], "size": {"0": 210, "1": 46}, "flags": {}, "order": 24, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 22}, {"name": "vae", "type": "VAE", "link": 10}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [34], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "VAEDecode"}, "color": "#232", "bgcolor": "#353"}, {"id": 12, "type": "ImageUpscaleWithModel", "pos": [2453.8764837009267, 343.9744881844717], "size": {"0": 241.79998779296875, "1": 46}, "flags": {}, "order": 19, "mode": 0, "inputs": [{"name": "upscale_model", "type": "UPSCALE_MODEL", "link": 35}, {"name": "image", "type": "IMAGE", "link": 13}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [15], "shape": 3}], "properties": {"Node name for S&R": "ImageUpscaleWithModel"}, "color": "#232", "bgcolor": "#353"}, {"id": 11, "type": "UpscaleModelLoader", "pos": [2406.8764837009267, 218.97448818446972], "size": {"0": 334.7138366699219, "1": 58.93333435058594}, "flags": {}, "order": 0, "mode": 0, "outputs": [{"name": "UPSCALE_MODEL", "type": "UPSCALE_MODEL", "links": [35], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "UpscaleModelLoader"}, "widgets_values": ["RealESRGAN_x4plus.pth"], "color": "#232", "bgcolor": "#353"}, {"id": 15, "type": "KSampler", "pos": [2788.7760981618703, 88.55636910146211], "size": {"0": 315, "1": 474}, "flags": {}, "order": 23, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 62}, {"name": "positive", "type": "CONDITIONING", "link": 71}, {"name": "negative", "type": "CONDITIONING", "link": 72}, {"name": "latent_image", "type": "LATENT", "link": 21}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [22], "shape": 3}], "properties": {"Node name for S&R": "KSampler"}, "widgets_values": [1108810846172325, "randomize", 25, 5.5, "euler", "normal", 0.4], "color": "#232", "bgcolor": "#353"}, {"id": 6, "type": "EmptyLatentImage", "pos": [1360, 41], "size": {"0": 263.0086364746094, "1": 106.84284973144531}, "flags": {}, "order": 1, "mode": 0, "outputs": [{"name": "LATENT", "type": "LATENT", "links": [], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "EmptyLatentImage"}, "widgets_values": [640, 768, 1]}, {"id": 30, "type": "OpenposePreprocessor", "pos": [967.50985734375, 403.4173353723145], "size": {"0": 339.9539489746094, "1": 153.00234985351562}, "flags": {}, "order": 9, "mode": 0, "inputs": [{"name": "image", "type": "IMAGE", "link": 77}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [76, 78], "shape": 3, "slot_index": 0}, {"name": "POSE_KEYPOINT", "type": "POSE_KEYPOINT", "links": null, "shape": 3}], "properties": {"Node name for S&R": "OpenposePreprocessor"}, "widgets_values": ["enable", "enable", "enable", 640], "color": "#323", "bgcolor": "#535"}, {"id": 1, "type": "CheckpointLoaderSimple", "pos": [-674, 59], "size": {"0": 377.24676513671875, "1": 100.37993621826172}, "flags": {}, "order": 2, "mode": 0, "outputs": [{"name": "MODEL", "type": "MODEL", "links": [66], "shape": 3, "slot_index": 0}, {"name": "CLIP", "type": "CLIP", "links": [1], "shape": 3}, {"name": "VAE", "type": "VAE", "links": null, "shape": 3}], "properties": {"Node name for S&R": "CheckpointLoaderSimple"}, "widgets_values": ["arthemyComics_v60Bakedvae.safetensors"], "color": "#432", "bgcolor": "#653"}, {"id": 8, "type": "VAELoader", "pos": [-663, 329], "size": {"0": 360.1028747558594, "1": 68.96443176269531}, "flags": {}, "order": 3, "mode": 0, "outputs": [{"name": "VAE", "type": "VAE", "links": [10, 12, 17, 28, 33], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "VAELoader"}, "widgets_values": ["BerrysMix.vae.safetensors"], "color": "#432", "bgcolor": "#653"}, {"id": 2, "type": "CLIPSetLastLayer", "pos": [-672, 216], "size": {"0": 371.94012451171875, "1": 58}, "flags": {}, "order": 7, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 1}], "outputs": [{"name": "CLIP", "type": "CLIP", "links": [63], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "CLIPSetLastLayer"}, "widgets_values": [-1], "color": "#432", "bgcolor": "#653"}, {"id": 26, "type": "CR LoRA Stack", "pos": [-259, 46], "size": {"0": 315, "1": 342}, "flags": {}, "order": 4, "mode": 0, "inputs": [{"name": "lora_stack", "type": "LORA_STACK", "link": null}], "outputs": [{"name": "LORA_STACK", "type": "LORA_STACK", "links": [60], "shape": 3, "slot_index": 0}, {"name": "show_help", "type": "STRING", "links": null, "shape": 3}], "properties": {"Node name for S&R": "CR LoRA Stack"}, "widgets_values": ["On", "1.5_perfect hands.safetensors", 0.8, 0.8, "Off", "None", 1, 1, "Off", "None", 1, 1], "color": "#432", "bgcolor": "#653"}, {"id": 27, "type": "CR Apply LoRA Stack", "pos": [-254, 439], "size": {"0": 303.7237854003906, "1": 77.73825073242188}, "flags": {}, "order": 10, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 66}, {"name": "clip", "type": "CLIP", "link": 63}, {"name": "lora_stack", "type": "LORA_STACK", "link": 60}], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [61, 62], "shape": 3, "slot_index": 0}, {"name": "CLIP", "type": "CLIP", "links": [64, 65], "shape": 3, "slot_index": 1}, {"name": "show_help", "type": "STRING", "links": null, "shape": 3}], "properties": {"Node name for S&R": "CR Apply LoRA Stack"}, "color": "#432", "bgcolor": "#653"}, {"id": 21, "type": "VAEEncode", "pos": [593.50985734375, 618.417335372314], "size": {"0": 283.8847961425781, "1": 68.25923156738281}, "flags": {}, "order": 11, "mode": 0, "inputs": [{"name": "pixels", "type": "IMAGE", "link": 31}, {"name": "vae", "type": "VAE", "link": 33}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [79], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "VAEEncode"}, "color": "#323", "bgcolor": "#535"}, {"id": 29, "type": "ControlNetLoader", "pos": [950.50985734375, 41.41733537231445], "size": {"0": 364.8855285644531, "1": 65.23101806640625}, "flags": {}, "order": 5, "mode": 0, "outputs": [{"name": "CONTROL_NET", "type": "CONTROL_NET", "links": [73], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "ControlNetLoader"}, "widgets_values": ["control_v11p_sd15_openpose.pth"], "color": "#323", "bgcolor": "#535"}, {"id": 31, "type": "PreviewImage", "pos": [978.50985734375, 604.417335372314], "size": {"0": 323.3812255859375, "1": 360.72991943359375}, "flags": {}, "order": 12, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 78}], "properties": {"Node name for S&R": "PreviewImage"}, "color": "#323", "bgcolor": "#535"}, {"id": 20, "type": "ImageScale", "pos": [594.50985734375, 421.4173353723145], "size": {"0": 283.74981689453125, "1": 143.86578369140625}, "flags": {}, "order": 8, "mode": 0, "inputs": [{"name": "image", "type": "IMAGE", "link": 30}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [31], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "ImageScale"}, "widgets_values": ["nearest-exact", 768, 640, "disabled"], "color": "#323", "bgcolor": "#535"}, {"id": 13, "type": "ImageScale", "pos": [2426.7760981618685, 450.5563691014664], "size": {"0": 315, "1": 130}, "flags": {}, "order": 21, "mode": 0, "inputs": [{"name": "image", "type": "IMAGE", "link": 15}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [16], "shape": 3}], "properties": {"Node name for S&R": "ImageScale"}, "widgets_values": ["nearest-exact", 1536, 1280, "disabled"], "color": "#232", "bgcolor": "#353"}, {"id": 28, "type": "ControlNetApplyAdvanced", "pos": [954.50985734375, 174.41733537231454], "size": {"0": 358.9978942871094, "1": 168.24929809570312}, "flags": {}, "order": 15, "mode": 0, "inputs": [{"name": "positive", "type": "CONDITIONING", "link": 68}, {"name": "negative", "type": "CONDITIONING", "link": 67}, {"name": "control_net", "type": "CONTROL_NET", "link": 73}, {"name": "image", "type": "IMAGE", "link": 76}], "outputs": [{"name": "positive", "type": "CONDITIONING", "links": [69, 71], "shape": 3, "slot_index": 0}, {"name": "negative", "type": "CONDITIONING", "links": [70, 72], "shape": 3, "slot_index": 1}], "properties": {"Node name for S&R": "ControlNetApplyAdvanced"}, "widgets_values": [0.8, 0, 0.8], "color": "#323", "bgcolor": "#535"}, {"id": 4, "type": "CLIPTextEncode", "pos": [116, 316], "size": {"0": 400, "1": 200}, "flags": {}, "order": 13, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 64}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [67], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["logo, logos, images, graphics, text,\nembedding:verybadimagenegative_v1.3, (3d), white eyes, layout, (worst quality:1.4),(low quality:1.4),(normal quality:1.3),lowres,watermark, title, (jpeg-artifacts:1.33), embedding:badhandv4, embedding:bad-artist, embedding:bad-artist-anime, "], "color": "#322", "bgcolor": "#533"}, {"id": 9, "type": "SaveImage", "pos": [3156.876483700934, 88.97448818447026], "size": {"0": 863.6416015625, "1": 866.5955810546875}, "flags": {}, "order": 25, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 34}], "properties": {}, "widgets_values": ["ComfyUI"], "color": "#232", "bgcolor": "#353"}, {"id": 10, "type": "VAEDecodeTiled", "pos": [2412.9542083476545, 90.06068897842411], "size": {"0": 315, "1": 78}, "flags": {}, "order": 17, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 11}, {"name": "vae", "type": "VAE", "link": 12}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [13], "shape": 3}], "properties": {"Node name for S&R": "VAEDecodeTiled"}, "widgets_values": [512], "color": "#232", "bgcolor": "#353"}, {"id": 17, "type": "SaveImage", "pos": [1696, 37], "size": {"0": 590.999267578125, "1": 849.8292846679688}, "flags": {}, "order": 20, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 29}], "properties": {}, "widgets_values": ["ComfyUI"]}, {"id": 16, "type": "VAEDecode", "pos": [1368, 834], "size": {"0": 246.53541564941406, "1": 57.41035079956055}, "flags": {}, "order": 18, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 27}, {"name": "vae", "type": "VAE", "link": 28}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [29], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "VAEDecode"}}, {"id": 18, "type": "LoadImage", "pos": [593, 36], "size": {"0": 292.46221923828125, "1": 340.5750732421875}, "flags": {}, "order": 6, "mode": 0, "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [30, 77], "shape": 3, "slot_index": 0}, {"name": "MASK", "type": "MASK", "links": null, "shape": 3}], "properties": {"Node name for S&R": "LoadImage"}, "widgets_values": ["posed model 1.jpg", "image"], "color": "#323", "bgcolor": "#535"}, {"id": 3, "type": "CLIPTextEncode", "pos": [123, 46], "size": {"0": 390.5724792480469, "1": 220.88401794433594}, "flags": {}, "order": 14, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 65}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [68], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["(graphic novel style:1.2), comic, (watercolor:1),\n\nattractive 20yo 1girl, (taylor swift:1.0), blue eyes, (red hair:1.1), (shoulder length hair:1.2),\n\n(plain white t-shirt:1.4), tight fitting t-shirt, (blue mini skirt:1.2),\n\nsmiling, happy, laughing, open mouth, (looking at camera:1.3),\n\n(atmosphere), coherent, continuity, epic, \n\nPerfect Hands, empty hands,\n\nplain background,"], "color": "#232", "bgcolor": "#353"}, {"id": 5, "type": "KSampler", "pos": [1360, 199], "size": {"0": 266.4233703613281, "1": 585.8148803710938}, "flags": {}, "order": 16, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 61}, {"name": "positive", "type": "CONDITIONING", "link": 69}, {"name": "negative", "type": "CONDITIONING", "link": 70}, {"name": "latent_image", "type": "LATENT", "link": 79}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [11, 27], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "KSampler"}, "widgets_values": [826278401544436, "fixed", 25, 7, "dpmpp_2m_sde", "exponential", 0.7000000000000001]}], "links": [[1, 1, 1, 2, 0, "CLIP"], [10, 8, 0, 7, 1, "VAE"], [11, 5, 0, 10, 0, "LATENT"], [12, 8, 0, 10, 1, "VAE"], [13, 10, 0, 12, 1, "IMAGE"], [15, 12, 0, 13, 0, "IMAGE"], [16, 13, 0, 14, 0, "IMAGE"], [17, 8, 0, 14, 1, "VAE"], [21, 14, 0, 15, 3, "LATENT"], [22, 15, 0, 7, 0, "LATENT"], [27, 5, 0, 16, 0, "LATENT"], [28, 8, 0, 16, 1, "VAE"], [29, 16, 0, 17, 0, "IMAGE"], [30, 18, 0, 20, 0, "IMAGE"], [31, 20, 0, 21, 0, "IMAGE"], [33, 8, 0, 21, 1, "VAE"], [34, 7, 0, 9, 0, "IMAGE"], [35, 11, 0, 12, 0, "UPSCALE_MODEL"], [60, 26, 0, 27, 2, "LORA_STACK"], [61, 27, 0, 5, 0, "MODEL"], [62, 27, 0, 15, 0, "MODEL"], [63, 2, 0, 27, 1, "CLIP"], [64, 27, 1, 4, 0, "CLIP"], [65, 27, 1, 3, 0, "CLIP"], [66, 1, 0, 27, 0, "MODEL"], [67, 4, 0, 28, 1, "CONDITIONING"], [68, 3, 0, 28, 0, "CONDITIONING"], [69, 28, 0, 5, 1, "CONDITIONING"], [70, 28, 1, 5, 2, "CONDITIONING"], [71, 28, 0, 15, 1, "CONDITIONING"], [72, 28, 1, 15, 2, "CONDITIONING"], [73, 29, 0, 28, 2, "CONTROL_NET"], [76, 30, 0, 28, 3, "IMAGE"], [77, 18, 0, 30, 0, "IMAGE"], [78, 30, 0, 31, 0, "IMAGE"], [79, 21, 0, 5, 3, "LATENT"]], "groups": [{"title": "Upscale", "bounding": [2383, 1, 1679, 1062], "color": "#3f789e", "font_size": 24, "locked": false}, {"title": "Models", "bounding": [-684, -28, 750, 555], "color": "#3f789e", "font_size": 24, "locked": false}, {"title": "Img2img + controlNet", "bounding": [583, -38, 743, 1013], "color": "#3f789e", "font_size": 24, "locked": false}], "config": {}, "extra": {}, "version": 0.4}}