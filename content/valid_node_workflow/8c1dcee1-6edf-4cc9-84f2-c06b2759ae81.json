{"description": "(This template is used for Workflow Contest)\nWhat this workflow does\n\ud83d\udc49 [Preparing UV diffuse texture for 3d human characters in 3dlender3d which can be exported to any 3d software]\n\nHow to use this workflow\n\ud83d\udc49 [The detailed workflow is in this link  https://youtu.be/rBblSTwsNwk?si=P2Lm-o_QFqk1N0Za ]\n\nTips about this workflow\n\ud83d\udc49 [use any photo editing software to edit the line art provided]\n\n\ud83c\udfa5 Video demo link (optional)\n\ud83d\udc49 [Please add here]", "name": "3d Human character model projection", "stars": "5.0", "number_reviews": 2, "workflow_like": 60, "workflow_view": 11700, "workflow_download": 1400, "workflow_comment": 1, "author_workflow": 1, "author_download": 1400, "author_like": 60, "author_view": 11700, "url": "https://openart.ai/workflows/owl_snarling_31/3d-human-character-model-projection/9aQdDmG7X6nqOjGQYER2", "workflow_json": {"last_node_id": 145, "last_link_id": 256, "nodes": [{"id": 21, "type": "LoraLoader", "pos": [-1180.5843098955788, 919.4141068087346], "size": {"0": 440, "1": 130}, "flags": {}, "order": 11, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 253}, {"name": "clip", "type": "CLIP", "link": 254}], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [11], "shape": 3, "slot_index": 0}, {"name": "CLIP", "type": "CLIP", "links": [24], "shape": 3, "slot_index": 1}], "properties": {"Node name for S&R": "LoraLoader"}, "widgets_values": ["more_details.safetensors", 0.24, 1]}, {"id": 130, "type": "LoraLoader", "pos": [-1180, 150], "size": {"0": 410, "1": 130}, "flags": {}, "order": 8, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 247}, {"name": "clip", "type": "CLIP", "link": 249}], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [186], "shape": 3, "slot_index": 0}, {"name": "CLIP", "type": "CLIP", "links": [188], "shape": 3, "slot_index": 1}], "properties": {"Node name for S&R": "LoraLoader"}, "widgets_values": ["more_details.safetensors", 0.32, 1]}, {"id": 105, "type": "CLIPTextEncode", "pos": [-1170, 320], "size": {"0": 390, "1": 160}, "flags": {"collapsed": false}, "order": 12, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 188}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [139], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["A Muscular African man, ((facing camera)), (((hair tied back))), soft light, head portrait, perfectly centered, frame symmetry, Brown skin, ((face wrinkles)), (45yo),  ((detailed face)), detailed skin, visible ears, beauty lighting, photo-realistic, 8k, highly detailed, full-length frame, High detail RAW color art, piercing, sharp focus, hyperrealism, black background, (hyperrealism:1.2), (photorealistic:1.2), shot with Canon EOS 5D Mark IV, detailed face, intricate details, combed hair, color dress"]}, {"id": 104, "type": "CLIPTextEncode", "pos": [-1190, 530], "size": {"0": 410, "1": 100}, "flags": {"collapsed": false}, "order": 9, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 250}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [137], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["embedding:easynegative, bad, text, ugly, shadows, head covering, face painting, cloth, child, out of frame, cut off, nsfw, grayscale, black and white, head cover, neck cover"]}, {"id": 83, "type": "EmptyLatentImage", "pos": [-1180, 680], "size": {"0": 400, "1": 110}, "flags": {}, "order": 0, "mode": 0, "outputs": [{"name": "LATENT", "type": "LATENT", "links": [114], "shape": 3}], "properties": {"Node name for S&R": "EmptyLatentImage"}, "widgets_values": [512, 512, 1]}, {"id": 18, "type": "LoadImage", "pos": [206.5218361331079, 140.73068968072585], "size": [360, 310], "flags": {"pinned": false, "collapsed": false}, "order": 1, "mode": 0, "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [21], "shape": 3, "slot_index": 0}, {"name": "MASK", "type": "MASK", "links": null, "shape": 3}], "title": "Load ControlNet Image (Pose)", "properties": {"Node name for S&R": "LoadImage"}, "widgets_values": ["fighter (13).png", "image"], "color": "#233", "bgcolor": "#355"}, {"id": 20, "type": "ImageScaleBy", "pos": [220, 480], "size": {"0": 350, "1": 82}, "flags": {}, "order": 7, "mode": 0, "inputs": [{"name": "image", "type": "IMAGE", "link": 21}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [20], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "ImageScaleBy"}, "widgets_values": ["area", 0.34]}, {"id": 16, "type": "ControlNetApply", "pos": [220, 690], "size": {"0": 350, "1": 100}, "flags": {}, "order": 15, "mode": 0, "inputs": [{"name": "conditioning", "type": "CONDITIONING", "link": 246}, {"name": "control_net", "type": "CONTROL_NET", "link": 19, "slot_index": 1}, {"name": "image", "type": "IMAGE", "link": 20}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [239], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "ControlNetApply"}, "widgets_values": [0.63]}, {"id": 17, "type": "ControlNetLoader", "pos": [220, 590], "size": {"0": 360, "1": 60}, "flags": {}, "order": 2, "mode": 0, "outputs": [{"name": "CONTROL_NET", "type": "CONTROL_NET", "links": [19], "shape": 3}], "properties": {"Node name for S&R": "ControlNetLoader"}, "widgets_values": ["control_v11p_sd15_lineart.pth"]}, {"id": 123, "type": "SaveImage", "pos": [-352.17453919532244, 1289.153200576565], "size": {"0": 930, "1": 440}, "flags": {"collapsed": false}, "order": 23, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 181}], "properties": {}, "widgets_values": ["ComfyUI"]}, {"id": 9, "type": "CheckpointLoaderSimple", "pos": [-1710, 910], "size": {"0": 315, "1": 98}, "flags": {}, "order": 3, "mode": 0, "outputs": [{"name": "MODEL", "type": "MODEL", "links": [247, 253], "shape": 3, "slot_index": 0}, {"name": "CLIP", "type": "CLIP", "links": [249, 250, 252, 254], "shape": 3, "slot_index": 1}, {"name": "VAE", "type": "VAE", "links": [16, 116], "shape": 3, "slot_index": 2}], "properties": {"Node name for S&R": "CheckpointLoaderSimple"}, "widgets_values": ["cyberrealistic_v30.safetensors"]}, {"id": 14, "type": "VAEDecode", "pos": [-1180, 1660], "size": {"0": 420, "1": 50}, "flags": {}, "order": 20, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 77}, {"name": "vae", "type": "VAE", "link": 16}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [180, 256], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "VAEDecode"}}, {"id": 19, "type": "EmptyLatentImage", "pos": [-1170, 1490], "size": {"0": 400, "1": 110}, "flags": {}, "order": 4, "mode": 0, "outputs": [{"name": "LATENT", "type": "LATENT", "links": [9], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "EmptyLatentImage"}, "widgets_values": [1664, 1024, 1]}, {"id": 10, "type": "CLIPTextEncode", "pos": [-1170, 1300], "size": {"0": 400, "1": 140}, "flags": {"collapsed": false}, "order": 10, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 252}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [8], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["embedding:easynegative, open mouth, ((face painting)), ((white hair, colorful hair, face painting)), public hair, neck cover, head cover, NSFW, nude, specular, shines"]}, {"id": 22, "type": "CLIPTextEncode", "pos": [-1170, 1090], "size": {"0": 410, "1": 170}, "flags": {"collapsed": false}, "order": 13, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 24}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [246], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["embedding:21charturnerv2, raw photo of a Muscular African man, ((muscular)), (side view of full body, front view of head, front view of full body, side view of head, and rear view of full body), ((mouth closed)), (((wearing traditional Indian dresses, colorful dress))),  Brown skin, ((black hair)), short hair, (hyperrealism:1.2), (photorealistic:1.2), shot with Canon EOS 5D Mark IV, detailed face, intricate details, combed hair, ((smooth body))"]}, {"id": 11, "type": "IPAdapter", "pos": [160, 890], "size": {"0": 420, "1": 170}, "flags": {"collapsed": false}, "order": 17, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 11}, {"name": "image", "type": "IMAGE", "link": 117, "slot_index": 1}, {"name": "clip_vision", "type": "CLIP_VISION", "link": 13, "slot_index": 2}, {"name": "mask", "type": "MASK", "link": null}], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [201], "shape": 3, "slot_index": 0}, {"name": "CLIP_VISION_OUTPUT", "type": "CLIP_VISION_OUTPUT", "links": [], "shape": 3, "slot_index": 1}], "title": "Load IPAdapter (SD 1.5 - Face)", "properties": {"Node name for S&R": "IPAdapter"}, "widgets_values": [1, "ip-adapter-plus-face_sd15.bin", "fp16"], "color": "#323", "bgcolor": "#535", "shape": 4}, {"id": 126, "type": "ImageUpscaleWithModel", "pos": [210, 1190], "size": {"0": 360, "1": 50}, "flags": {"collapsed": false}, "order": 21, "mode": 0, "inputs": [{"name": "upscale_model", "type": "UPSCALE_MODEL", "link": 179}, {"name": "image", "type": "IMAGE", "link": 180}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [181], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "ImageUpscaleWithModel"}}, {"id": 125, "type": "UpscaleModelLoader", "pos": [-362.17453919532244, 1179.153200576565], "size": {"0": 540, "1": 70}, "flags": {}, "order": 5, "mode": 0, "outputs": [{"name": "UPSCALE_MODEL", "type": "UPSCALE_MODEL", "links": [179], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "UpscaleModelLoader"}, "widgets_values": ["Real_HAT_GAN_SRx4.pth"]}, {"id": 12, "type": "CLIPVisionLoader", "pos": [-349.19747158928703, 897.1615855658725], "size": {"0": 490, "1": 70}, "flags": {"collapsed": false}, "order": 6, "mode": 0, "outputs": [{"name": "CLIP_VISION", "type": "CLIP_VISION", "links": [13], "shape": 3}], "properties": {"Node name for S&R": "CLIPVisionLoader"}, "widgets_values": ["CLIP-ViT-H-14-laion2B-s32B-b79K.bin"]}, {"id": 84, "type": "VAEDecode", "pos": [-700, 660], "size": {"0": 310, "1": 120}, "flags": {}, "order": 16, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 115}, {"name": "vae", "type": "VAE", "link": 116}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [117, 135], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "VAEDecode"}}, {"id": 103, "type": "PreviewImage", "pos": [-350, 150], "size": {"0": 450, "1": 640}, "flags": {"collapsed": false}, "order": 18, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 135}], "properties": {"Node name for S&R": "PreviewImage"}}, {"id": 81, "type": "KSampler", "pos": [-700, 140], "size": {"0": 320, "1": 470}, "flags": {"collapsed": false}, "order": 14, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 186}, {"name": "positive", "type": "CONDITIONING", "link": 139}, {"name": "negative", "type": "CONDITIONING", "link": 137}, {"name": "latent_image", "type": "LATENT", "link": 114, "slot_index": 3}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [115], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "KSampler"}, "widgets_values": [503, "fixed", 19, 4, "dpmpp_2m", "karras", 1]}, {"id": 8, "type": "KSampler", "pos": [-720, 920], "size": {"0": 270, "1": 470}, "flags": {"collapsed": false}, "order": 19, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 201, "slot_index": 0}, {"name": "positive", "type": "CONDITIONING", "link": 239, "slot_index": 1}, {"name": "negative", "type": "CONDITIONING", "link": 8}, {"name": "latent_image", "type": "LATENT", "link": 9, "slot_index": 3}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [77], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "KSampler"}, "widgets_values": [503, "fixed", 20, 3.95, "dpmpp_2m_sde_gpu", "karras", 1]}, {"id": 145, "type": "SaveImage", "pos": [-730, 1440], "size": {"0": 280, "1": 270}, "flags": {}, "order": 22, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 256}], "properties": {}, "widgets_values": ["ComfyUI"]}], "links": [[8, 10, 0, 8, 2, "CONDITIONING"], [9, 19, 0, 8, 3, "LATENT"], [11, 21, 0, 11, 0, "MODEL"], [13, 12, 0, 11, 2, "CLIP_VISION"], [16, 9, 2, 14, 1, "VAE"], [19, 17, 0, 16, 1, "CONTROL_NET"], [20, 20, 0, 16, 2, "IMAGE"], [21, 18, 0, 20, 0, "IMAGE"], [24, 21, 1, 22, 0, "CLIP"], [77, 8, 0, 14, 0, "LATENT"], [114, 83, 0, 81, 3, "LATENT"], [115, 81, 0, 84, 0, "LATENT"], [116, 9, 2, 84, 1, "VAE"], [117, 84, 0, 11, 1, "IMAGE"], [135, 84, 0, 103, 0, "IMAGE"], [137, 104, 0, 81, 2, "CONDITIONING"], [139, 105, 0, 81, 1, "CONDITIONING"], [179, 125, 0, 126, 0, "UPSCALE_MODEL"], [180, 14, 0, 126, 1, "IMAGE"], [181, 126, 0, 123, 0, "IMAGE"], [186, 130, 0, 81, 0, "MODEL"], [188, 130, 1, 105, 0, "CLIP"], [201, 11, 0, 8, 0, "MODEL"], [239, 16, 0, 8, 1, "CONDITIONING"], [246, 22, 0, 16, 0, "CONDITIONING"], [247, 9, 0, 130, 0, "MODEL"], [249, 9, 1, 130, 1, "CLIP"], [250, 9, 1, 104, 0, "CLIP"], [252, 9, 1, 10, 0, "CLIP"], [253, 9, 0, 21, 0, "MODEL"], [254, 9, 1, 21, 1, "CLIP"], [256, 14, 0, 145, 0, "IMAGE"]], "groups": [{"title": "Face creation", "bounding": [-1226, 54, 1365, 753], "color": "#4400ff", "font_size": 24, "locked": false}, {"title": "ipadaptor", "bounding": [-397, 821, 1000, 248], "color": "#ffa200", "font_size": 24, "locked": false}, {"title": "Group", "bounding": [166, 62, 437, 748], "color": "#fbff00", "font_size": 24, "locked": false}, {"title": "Body creation+Face", "bounding": [-1226, 829, 807, 927], "color": "#ff00ea", "font_size": 24, "locked": false}, {"title": "upscale", "bounding": [-395, 1093, 994, 659], "color": "#f00000", "font_size": 24, "locked": false}], "config": {}, "extra": {}, "version": 0.4}}